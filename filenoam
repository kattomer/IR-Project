from collections import defaultdict

def min_max_normalize(dictionary):
    min_value = min(dictionary.values())
    max_value = max(dictionary.values())
    denominator = max_value - min_value
    if denominator == 0:
        return dictionary
    
    for key in dictionary:
        dictionary[key] = (dictionary[key] - min_value) / denominator
    return dictionary

def search_anchor(query, index):
    dict_cosine_sim = defaultdict(float)
    query_dict = dict(term_frequency(query, 0))
    query_terms_set = set(query_dict.keys())
    index_df_set = set(index.df.keys())

    # Only process terms that exist in both the query and index
    common_terms = query_terms_set.intersection(index_df_set)

    for term in common_terms:
        posting_list = index.read_a_posting_list(".", term, "noam209263805")
        for doc_id, freq in posting_list:
            dict_cosine_sim[doc_id] += freq

    # Normalize the values in dict_cosine_sim
    dict_cosine_sim_normalized = min_max_normalize(dict_cosine_sim)

    # Sort and select the top 100 documents
    sorted_docs = sorted(dict_cosine_sim_normalized.items(), key=lambda x: x[1], reverse=True)
    top_100_docs = sorted_docs[:100]

    return top_100_docs


# if ngram == true -> do title_2_words
# if ngram == false -> do title_1

def search_title(query, index, ngram = False):

    dict_cosine_sim = defaultdict(float)
    query_dict = dict(term_frequency(query, 0))
    query_list_keys = list(query_dict.keys())
    index_df_list_keys = list(index.df.keys())


    if not ngram:
        for term in query_list_keys:
            if term in index_df_list_keys:
                posting_list = index.read_a_posting_list(".", term, "noam209263805")
                for doc_id, freq in posting_list:
                    x = re.sub(r'[^\w]', ' ', index.doc_id_title[doc_id]).split(" ")
                    dict_cosine_sim[doc_id] += freq / len(x)
    else:
        for i, term in enumerate(enquery_list_keys):
            if i == (len(enquery_list_keys) - 1):
                break

            if term in index_df_list_keys:
                posting_list = index.read_a_posting_list(".", enquery_list_keys[i] + " " + enquery_list_keys[i+1], "noam209263805")
                for doc_id, freq in posting_list:
                    x = re.sub(r'[^\w]', ' ', index.doc_id_title[doc_id]).split(" ")
                    dict_cosine_sim[doc_id] += freq / len(x)

    sorted_docs = sorted(dict_cosine_sim.items(), key=lambda x: x[1], reverse=True)
    top_100_docs = sorted_docs[:100]
    return top_100_docs
