{"cells":[{"cell_type":"markdown","id":"a00e032c","metadata":{"id":"hWgiQS0zkWJ5"},"source":["***Important*** DO NOT CLEAR THE OUTPUT OF THIS NOTEBOOK AFTER EXECUTION!!!"]},{"cell_type":"code","execution_count":21,"id":"5ac36d3a","metadata":{"id":"c0ccf76b","nbgrader":{"grade":false,"grade_id":"cell-Worker_Count","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"cf88b954-f39a-412a-d87e-660833e735b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["NAME          PLATFORM  PRIMARY_WORKER_COUNT  SECONDARY_WORKER_COUNT  STATUS   ZONE           SCHEDULED_DELETE\r\n","cluster-3842  GCE       3                                             RUNNING  us-central1-a\r\n"]}],"source":["# if the following command generates an error, you probably didn't enable \n","# the cluster security option \"Allow API access to all Google Cloud services\"\n","# under Manage Security â†’ Project Access when setting up the cluster\n","!gcloud dataproc clusters list --region us-central1"]},{"cell_type":"markdown","id":"51cf86c5","metadata":{"id":"01ec9fd3"},"source":["# Imports & Setup"]},{"cell_type":"code","execution_count":22,"id":"bf199e6a","metadata":{"id":"32b3ec57","nbgrader":{"grade":false,"grade_id":"cell-Setup","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"fc0e315d-21e9-411d-d69c-5b97e4e5d629"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -q google-cloud-storage==1.43.0\n","!pip install -q graphframes"]},{"cell_type":"code","execution_count":23,"id":"d8f56ecd","metadata":{"id":"5609143b","nbgrader":{"grade":false,"grade_id":"cell-Imports","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"a24aa24b-aa75-4823-83ca-1d7deef0f0de"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["import pyspark\n","import sys\n","from collections import Counter, OrderedDict, defaultdict\n","import itertools\n","from itertools import islice, count, groupby\n","import pandas as pd\n","import os\n","import re\n","from operator import itemgetter\n","import nltk\n","from nltk.stem.porter import *\n","from nltk.corpus import stopwords\n","from time import time\n","from pathlib import Path\n","import pickle\n","import pandas as pd\n","from google.cloud import storage\n","import math\n","import builtins as pybuiltins\n","\n","\n","import hashlib\n","def _hash(s):\n","    return hashlib.blake2b(bytes(s, encoding='utf8'), digest_size=5).hexdigest()\n","\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":24,"id":"38a897f2","metadata":{"id":"b10cc999","nbgrader":{"grade":false,"grade_id":"cell-jar","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"8f93a7ec-71e0-49c1-fc81-9af385849a90"},"outputs":[{"name":"stdout","output_type":"stream","text":["-rw-r--r-- 1 root root 247882 Feb 29 16:35 /usr/lib/spark/jars/graphframes-0.8.2-spark3.1-s_2.12.jar\r\n"]}],"source":["# if nothing prints here you forgot to include the initialization script when starting the cluster\n","!ls -l /usr/lib/spark/jars/graph*"]},{"cell_type":"code","execution_count":25,"id":"47900073","metadata":{"id":"d3f86f11","nbgrader":{"grade":false,"grade_id":"cell-pyspark-import","locked":true,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext, SparkConf, SparkFiles\n","from pyspark.sql import SQLContext\n","from graphframes import *"]},{"cell_type":"code","execution_count":26,"id":"72bed56b","metadata":{"id":"5be6dc2a","nbgrader":{"grade":false,"grade_id":"cell-spark-version","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"07b4e22b-a252-42fb-fe46-d9050e4e7ca8","scrolled":false},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-3842-m.us-central1-a.c.ornate-artifact-414010.internal:39665\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f6723a03490>"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":27,"id":"980e62a5","metadata":{"id":"7adc1bf5","nbgrader":{"grade":false,"grade_id":"cell-bucket_name","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# Put your bucket name below and make sure you can access it without an error\n","bucket_name = '207219783b2' \n","full_path = f\"gs://{bucket_name}/\"\n","paths=[]\n","\n","client = storage.Client()\n","blobs = client.list_blobs(bucket_name)\n","for b in blobs:\n","    if b.name != 'graphframes.sh' and not b.name.startswith(\"postings_gcp\"):\n","        paths.append(full_path+b.name)"]},{"cell_type":"code","execution_count":28,"id":"e4c523e7","metadata":{"id":"b1af29c9","scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["parquetFile = spark.read.parquet(*paths)\n","doc_title_pairs = parquetFile.select(\"title\", \"id\").rdd\n","# doc_anchor_pairs = parquetFile.select(\"anchor_text\", \"id\").rdd\n","# doc_body_pairs = parquetFile.select(\"text\", \"id\").rdd"]},{"cell_type":"code","execution_count":29,"id":"121fe102","metadata":{"id":"04371c88","outputId":"327fe81b-80f4-4b3a-8894-e74720d92e35"},"outputs":[{"name":"stdout","output_type":"stream","text":["inverted_index_gcp.py\r\n"]}],"source":["# if nothing prints here you forgot to upload the file inverted_index_gcp.py to the home dir\n","%cd -q /home/dataproc\n","!ls inverted_index_gcp.py"]},{"cell_type":"code","execution_count":30,"id":"57c101a8","metadata":{"id":"2d3285d8","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["24/02/29 17:28:33 WARN SparkContext: The path /home/dataproc/inverted_index_gcp.py has been added already. Overwriting of added paths is not supported in the current version.\n"]}],"source":["# adding our python module to the cluster\n","sc.addFile(\"/home/dataproc/inverted_index_gcp.py\")\n","sys.path.insert(0,SparkFiles.getRootDirectory())"]},{"cell_type":"code","execution_count":11,"id":"c259c402","metadata":{"id":"2477a5b9"},"outputs":[],"source":["from inverted_index_gcp import InvertedIndex"]},{"cell_type":"markdown","id":"5540c727","metadata":{"id":"72bcf46a"},"source":["**Project**\n"]},{"cell_type":"code","execution_count":12,"id":"92b0101a","metadata":{},"outputs":[],"source":["# stop words\n","english_stopwords = frozenset(stopwords.words('english'))\n","corpus_stopwords = ['category', 'references', 'also', 'links', 'extenal', 'see', 'thumb']\n","RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){2,24}\"\"\", re.UNICODE)\n","all_stopwords = english_stopwords.union(corpus_stopwords)\n","\n","\n","# tokenize and stemming\n","def tokenize_stemming(text):\n","    list_token = []\n","    stemmer = PorterStemmer()\n","    tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n","    for token in tokens:\n","        if token not in english_stopwords:\n","            list_token.append(stemmer.stem(token))\n","    return list_token\n"]},{"cell_type":"code","execution_count":13,"id":"29fba0c2","metadata":{},"outputs":[],"source":["# tf\n","# normalizion by max frequency term\n","def term_frequency(text, id):\n","    tokens = tokenize_stemming(text)\n","#     tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n","\n","    # Count the frequency of each word that is not a stopword\n","    word_freq = {}\n","    doc_size = 0\n","\n","    for token in tokens:\n","        doc_size += 1\n","        if token not in all_stopwords:\n","            if token not in word_freq:\n","                word_freq[token] = 1\n","            else:\n","                word_freq[token] += 1\n","\n","    lst_tuples = [(token, (id, freq, doc_size)) for token, freq in word_freq.items()]\n","    return lst_tuples\n","\n","\n","def reduce_word_counts(unsorted_pl):\n","  sorted_pl = sorted(unsorted_pl, key=lambda x: x[0])\n","  return sorted_pl\n","\n","# df\n","def calculate_df(postings):\n","  rdd_token_doc_freq = postings.map(lambda x: (x[0], len(x[1]))).reduceByKey(lambda a, b: a + b)\n","  return rdd_token_doc_freq\n","\n","\n","# doc len\n","# def doc_lenght(text, doc_id):\n","#   tokens = tokenize_stemming(text)\n","#   return((doc_id,len(tokens)))\n"]},{"cell_type":"code","execution_count":14,"id":"aec0f102","metadata":{},"outputs":[],"source":["\n","\n","NUM_BUCKETS = 124\n","def token2bucket_id(token):\n","  return int(_hash(token),16) % NUM_BUCKETS\n","\n","def partition_postings_and_write(postings, index_name):\n","  def map_to_buckets(pair):\n","        word, posting_list = pair\n","        bucket_id = token2bucket_id(word)\n","        return bucket_id, [(word, posting_list)]\n","\n","  def reduce_to_disk(bucket, word_posting_lists):\n","    # Write posting lists for the bucket to disk\n","    posting_locs = InvertedIndex.write_a_posting_list((bucket, word_posting_lists), f'bucket_{index_name}', bucket_name)\n","    return posting_locs\n","\n","  # Partition the postings into buckets\n","  buckets = postings.map(map_to_buckets)\n","\n","  # Group postings by bucket ID\n","  grouped_buckets = buckets.reduceByKey(lambda x, y: x + y)\n","\n","  # Write each bucket to disk and get posting locations\n","  bucket_posting_locs = grouped_buckets.map(lambda x: reduce_to_disk(*x))\n","\n","  return bucket_posting_locs\n","\n","def create_posting_locs(index_name, postings_filtered):\n","  posting_locs_list = partition_postings_and_write(postings_filtered, index_name).collect()\n","\n","  super_posting_locs = defaultdict(list)\n","  for blob in client.list_blobs(bucket_name, prefix=f'bucket_{index_name}'):\n","    if not blob.name.endswith(\"pickle\"):\n","        continue\n","    with blob.open(\"rb\") as f:\n","        posting_locs = pickle.load(f)\n","        for k, v in posting_locs.items():\n","            super_posting_locs[k].extend(v)\n","  return super_posting_locs"]},{"cell_type":"code","execution_count":15,"id":"f3ad8fea","metadata":{"id":"a4b6ee29","nbgrader":{"grade":false,"grade_id":"cell-token2bucket","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["def create_index(index_name, doc_pairs):\n","\n","    word_counts = doc_pairs.flatMap(lambda x: term_frequency(x[0], x[1]))\n","    postings = word_counts.groupByKey().mapValues(reduce_word_counts)\n","    postings_filtered = postings.filter(lambda x: len(x[1])>20)\n","\n","#     dl_rdd = doc_pairs.map(lambda x: doc_lenght(x[0], x[1]))\n","#     dl = dl_rdd.collectAsMap()\n","    w2df = calculate_df(postings_filtered)\n","    w2df_dict = w2df.collectAsMap()\n","\n","    # Create inverted index instance\n","    inverted = InvertedIndex()\n","    inverted.df = w2df_dict\n","    inverted.N = doc_pairs.count()\n","#     inverted.doc_len = dl\n","    inverted.posting_locs = create_posting_locs(index_name, postings_filtered)\n","\n","    inverted.write_index('.', f'index_{index_name}')\n","\n","    index_src = f\"index_{index_name}.pkl\"\n","    dir = f\"bucket_{index_name}\"\n","    index_dst = f'gs://{bucket_name}/{dir}/{index_src}'\n","    !gsutil cp $index_src $index_dst\n","    \n","#     return inverted"]},{"cell_type":"code","execution_count":16,"id":"b3744a8b","metadata":{},"outputs":[],"source":["# TUPLE_SIZE = 6\n","# TF_MASK = 2 ** 16 - 1 # Masking the 16 low bits of an integer\n","# from contextlib import closing\n","\n","\n","# def read_posting_list(inverted, w):\n","#   with closing(MultiFileReader(\".\", bucket_name)) as reader:\n","#     locs = inverted.posting_locs[w]\n","#     b = reader.read(locs, inverted.df[w] * TUPLE_SIZE)\n","#     posting_list = []\n","#     for i in range(inverted.df[w]):\n","#       doc_id = int.from_bytes(b[i*TUPLE_SIZE:i*TUPLE_SIZE+4], 'big')\n","#       tf = int.from_bytes(b[i*TUPLE_SIZE+4:(i+1)*TUPLE_SIZE], 'big')\n","#       posting_list.append((doc_id, tf))\n","#     return posting_list"]},{"cell_type":"code","execution_count":17,"id":"1d534a19","metadata":{},"outputs":[],"source":["# weight = tf*idf\n","def calculate_tf_idf(index, term, tf, doc_id):\n","  tf_idf = tf* (math.log2(index.N/index.df[term]))\n","  return tf_idf\n","\n","\n","def cosine_similarity(query, index):\n","    \"\"\" Returns: {doc_id:cosine score} \"\"\"\n","\n","    dict_cosine_sim = {}\n","    doc_weights_dict = {}\n","    query_dict = dict(term_frequency(query ,0))\n","\n","    # create lists of keys and values from the query_dict\n","    query_list_keys = list(query_dict.keys())\n","    query_list_values = list(query_dict.values())\n","\n","    # create list of items from index.df dictionery keys\n","    index_df_list_keys = list(index.df.keys())\n","#     print(index.df['considered'])\n","#     print(query_dict)\n","\n","\n","    for term in query_list_keys:\n","      w_term_query = (query_dict[term][1]/len(query))* math.log2(index.N/index.df[term])\n","\n","      if term in index_df_list_keys:\n","        posting_list = index.read_a_posting_list(\".\", term, bucket_name)\n","        \n","        for doc_id, freq, doc_len in posting_list:  \n","          w_term_doc = calculate_tf_idf(index, term, freq/doc_len, doc_id)\n","          if doc_id in dict_cosine_sim.keys():\n","            dict_cosine_sim[doc_id] += (w_term_doc)*(w_term_query)\n","            doc_weights_dict[doc_id] += (w_term_doc) ** 2\n","          else:\n","            dict_cosine_sim[doc_id] = (w_term_doc)*(w_term_query)\n","            doc_weights_dict[doc_id] = (w_term_doc) ** 2\n","\n","\n","    for doc_id in list(dict_cosine_sim.keys()):\n","      Word_doc_id__weight = doc_weights_dict[doc_id];\n","      dict_cosine_sim[doc_id] /= ( math.sqrt(pybuiltins.sum(value[1] ** 2 for value in query_list_values) * Word_doc_id__weight ))\n","\n","\n","\n","    sorted_docs = sorted(dict_cosine_sim.items(), key=lambda x: x[1], reverse=True)\n","\n","    print(sorted_docs)\n","    return dict_cosine_sim\n"]},{"cell_type":"code","execution_count":18,"id":"45428cac","metadata":{},"outputs":[],"source":["# def BM25(query, index, k, b, avg_doclen):\n","#     bm_score = {}\n","#     # create lists of keys and values from the query_dict\n","#     query_list_keys = list(query_dict.keys())\n","#     query_list_values = list(query_dict.values())\n","#     # create list of items from index.df dictionery keys\n","#     index_df_list_keys = list(index.df.keys())\n","    \n","#     idf_dict = calc_idf(query, N, index)\n","    \n","#     for term in query_list_keys:\n","#         if term in index_df_list_keys:\n","#             posting_list = index.read_a_posting_list(\".\", term, bucket_name)\n","#             for doc_id, freq in posting_list:\n","#                 B = 1 - b + b * (index.dl[doc_id] / avg_doclen)\n","#                 idf = idf_dict[term]\n","#                 tf = freq / index.dl[doc_id]\n","#                 if doc_id in bm_score:\n","#                     bm_score[doc_id] += (idf * freq * (k + 1)) / ((freq + B * k))\n","#                 else:\n","#                     bm_score[doc_id] = (idf * freq * (k + 1)) / ((freq + B * k))\n","    \n","#     return dict(sorted(bm_score.items(), key=lambda x: x[1], reverse=True))\n","            "]},{"cell_type":"code","execution_count":19,"id":"7b95468d","metadata":{},"outputs":[],"source":["import time\n","def search_by_title(inverted, query):\n","    \"\"\" Returns: n best docs \"\"\"\n","    start_time = time.time()  # Record the start time\n","\n","    query_filterd = tokenize_stemming(query)\n","    cosSim_score = cosine_similarity(query, inverted)\n","\n","    end_time = time.time()  # Record the end time\n","    execution_time = end_time - start_time  # Calculate the execution time\n","    print(\"Function execution time:\", execution_time, \"seconds\")\n","    return cosSim_score"]},{"cell_type":"code","execution_count":20,"id":"147fda3e","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Copying file://index_title.pkl [Content-Type=application/octet-stream]...\n","/ [1 files][  1.8 MiB/  1.8 MiB]                                                \n","Operation completed over 1 objects/1.8 MiB.                                      \n"]},{"ename":"NotFound","evalue":"404 GET https://storage.googleapis.com/download/storage/v1/b/207219783b2/o/bucket_title%2Findex_title.pkl?alt=media: No such object: 207219783b2/bucket_title/index_title.pkl: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidResponse\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/client.py\u001b[0m in \u001b[0;36mdownload_blob_to_file\u001b[0;34m(self, blob_or_uri, file_obj, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m             blob_or_uri._do_download(\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0mtransport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/blob.py\u001b[0m in \u001b[0;36m_do_download\u001b[0;34m(self, transport, file_obj, download_url, headers, start, end, raw_download, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_headers_from_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/download.py\u001b[0m in \u001b[0;36mconsume\u001b[0;34m(self, transport, timeout)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         return _request_helpers.wait_and_retry(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mretriable_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_status_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/_request_helpers.py\u001b[0m in \u001b[0;36mwait_and_retry\u001b[0;34m(func, get_status_code, retry_strategy)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_CONNECTION_ERROR_CLASSES\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/download.py\u001b[0m in \u001b[0;36mretriable_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/_download.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         _helpers.require_status_code(\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ACCEPTABLE_STATUS_CODES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_status_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/_helpers.py\u001b[0m in \u001b[0;36mrequire_status_code\u001b[0;34m(response, status_codes, get_status_code, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         raise common.InvalidResponse(\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidResponse\u001b[0m: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_10068/3411087254.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_title_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvertedIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bucket_title\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'index_title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/hadoop/spark/tmp/spark-8119fb42-45b9-41db-8086-7bd9996023cb/userFiles-97821385-3c1a-4fc7-9cde-75fb7ebf2842/inverted_index_gcp.py\u001b[0m in \u001b[0;36mread_index\u001b[0;34m(base_dir, name, bucket_name)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbucket_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mget_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/fileio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# entire file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 result += self._blob.download_as_bytes(\n\u001b[0m\u001b[1;32m    139\u001b[0m                     \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfetch_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfetch_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/blob.py\u001b[0m in \u001b[0;36mdownload_as_bytes\u001b[0;34m(self, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   1415\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_require_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m         \u001b[0mstring_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1417\u001b[0;31m         client.download_blob_to_file(\n\u001b[0m\u001b[1;32m   1418\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mstring_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/client.py\u001b[0m in \u001b[0;36mdownload_blob_to_file\u001b[0;34m(self, blob_or_uri, file_obj, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   1124\u001b[0m             )\n\u001b[1;32m   1125\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mresumable_media\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidResponse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m             \u001b[0m_raise_from_invalid_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     def list_blobs(\n","\u001b[0;32m/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/blob.py\u001b[0m in \u001b[0;36m_raise_from_invalid_response\u001b[0;34m(error)\u001b[0m\n\u001b[1;32m   4464\u001b[0m     )\n\u001b[1;32m   4465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4466\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFound\u001b[0m: 404 GET https://storage.googleapis.com/download/storage/v1/b/207219783b2/o/bucket_title%2Findex_title.pkl?alt=media: No such object: 207219783b2/bucket_title/index_title.pkl: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)"]}],"source":["create_index(\"title\", doc_title_pairs)\n","idx = InvertedIndex.read_index(\"bucket_title\", 'index_title', bucket_name)\n"]},{"cell_type":"code","execution_count":78,"id":"71e6b1c9","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["42\n","{'considered': (0, 1, 3)}\n","[(1143671, 0.8193219082598878), (17816236, 0.8193219082598878), (26978760, 0.8193219082598878), (50917713, 0.8193219082598878), (54336970, 0.8193219082598878), (56540992, 0.8193219082598878), (63182560, 0.8193219082598878), (302808, 0.8193219082598877), (304831, 0.8193219082598877), (346644, 0.8193219082598877), (895368, 0.8193219082598877), (1317337, 0.8193219082598877), (1638787, 0.8193219082598877), (3445895, 0.8193219082598877), (10279397, 0.8193219082598877), (10383045, 0.8193219082598877), (12278801, 0.8193219082598877), (15173049, 0.8193219082598877), (15261154, 0.8193219082598877), (18592966, 0.8193219082598877), (18750836, 0.8193219082598877), (21298438, 0.8193219082598877), (22095950, 0.8193219082598877), (23616514, 0.8193219082598877), (28832368, 0.8193219082598877), (45257468, 0.8193219082598877), (47204279, 0.8193219082598877), (50768211, 0.8193219082598877), (53330015, 0.8193219082598877), (54860987, 0.8193219082598877), (57741901, 0.8193219082598877), (58667750, 0.8193219082598877), (221332, 0.8193219082598876), (9894205, 0.8193219082598876), (12819734, 0.8193219082598876), (17956828, 0.8193219082598876), (18197487, 0.8193219082598876), (21294298, 0.8193219082598876), (25571093, 0.8193219082598876), (41011935, 0.8193219082598876), (54444447, 0.8193219082598876), (54729708, 0.8193219082598876)]\n","Function execution time: 0.12263226509094238 seconds\n"]}],"source":["# query = \"genetics\"\n","query = \"Who is considered the\"\n","res = search_by_title(idx, query)"]},{"cell_type":"code","execution_count":null,"id":"8d3440ec","metadata":{},"outputs":[],"source":[]}],"metadata":{"celltoolbar":"Create Assignment","colab":{"collapsed_sections":[],"name":"assignment3_gcp.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}
